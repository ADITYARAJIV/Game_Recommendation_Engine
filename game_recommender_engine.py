# -*- coding: utf-8 -*-
"""Game recommender engine.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z1MXl6_hZPqe1_w2fPSx2ykWWAE4UZrx
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import random
from nltk.tokenize import word_tokenize
from gensim.models import FastText
import pickle
warnings.filterwarnings('ignore')

df_google_games = pd.read_csv('googleplaystore.csv')

df_google_games.head()

df_mobygames1 = pd.read_excel('MobyGames1.xlsx')
df_mobygames2 = pd.read_excel('MobyGames2.xlsx')
df_mobygames3 = pd.read_excel('MobyGames3.xlsx')
df_mobygames4 = pd.read_excel('MobyGames4.xlsx')
df_mobygames5 = pd.read_excel('MobyGames5.xlsx')
df_mobygames6 = pd.read_excel('MobyGames6.xlsx')

df_mobygames1.head()

df_video_games = pd.read_csv('Video_Games.csv')

df_video_games.head()

df_appstore_games = pd.read_csv('appstore_games.csv')

df_appstore_games.head()

df_appstore_games.info()

df_appstore_games_required = df_appstore_games[['Name', 'Average User Rating', 'Genres', 'Current Version Release Date']]

df_appstore_games_required.head()

df_appstore_games_required.info()

df_appstore_games_required.rename(columns = {'Average User Rating': 'Rating', 'Genres': 'Genre', 'Current Version Release Date': 'Released_date'}, inplace = True)

df_appstore_games_required.info()

df_appstore_games_required['Released_date'] = pd.to_datetime(df_appstore_games_required['Released_date'])

df_appstore_games_required.info()

df_appstore_games_required['Released_year'] = df_appstore_games_required['Released_date'].dt.year

df_appstore_games_required.info()

df_appstore_games_required.describe()

df_appstore_games_required['Rating'] = df_appstore_games_required['Rating'].fillna(round(np.random.uniform(3.5, 5), 2))

df_appstore_games_required.info()

df_video_games.head()

df_video_games_required = df_video_games[['Name', 'Genre', 'Release_year', 'Rating']]

df_video_games_required.head()

df_video_games_required.info()

df_video_games_required.describe()

df_video_games_required['Rating'] = df_video_games_required['Rating'].fillna(round(np.random.uniform(65, 98), 2))

df_video_games_required.info()

df_video_games_required.describe()

df_video_games_required = df_video_games_required.dropna()

df_video_games_required.info()

df_video_games_required.rename(columns = {'Release_year': 'Released_year'}, inplace = True)

df_video_games_required['Released_year'] = df_video_games_required['Released_year'].astype('int')

df_video_games_required.info()

df_google_games.head()

df_google_games_required = df_google_games[['App', 'Category', 'Rating', 'Last Updated']]

df_google_games_required.info()

df_google_games_required.rename(columns = {'App': 'Name', 'Category': 'Genre', 'Last Updated': 'Released_date'}, inplace = True)

df_google_games_required.info()

df_google_games_required.describe()

df_google_games_required['Rating'] = df_google_games_required['Rating'].fillna(round(np.random.uniform(4, 5), 2))

df_google_games_required['Released_date'] = df_google_games_required['Released_date'].str.replace('1.0.19', 'January 1, 2019')

df_google_games_required['Released_date'] = pd.to_datetime(df_google_games_required['Released_date'])

df_google_games_required.info()

df_google_games_required['Released_year'] = df_google_games_required['Released_date'].dt.year

df_google_games_required.info()

df_mobygames = pd.concat([df_mobygames1, df_mobygames2, df_mobygames3, df_mobygames4, df_mobygames5, df_mobygames6], axis = 0)

df_mobygames.info()

df_mobygames.head()

df_mobygames_required = df_mobygames[['Title1', 'Genres', 'Released', 'Moby_Score']]

df_mobygames_required.info()

df_mobygames_required.rename(columns = {'Title1': 'Name', 'Genres': 'Genre', 'Moby_Score': 'Rating'}, inplace = True)

df_mobygames_required.info()

df_mobygames_required['Released'] = df_mobygames_required['Released'].fillna(df_mobygames['Released_year'])

df_mobygames_required.info()

df_mobygames_required.describe()

df_mobygames_required['Rating'] = df_mobygames_required['Rating'].fillna(round(np.random.uniform(7.5, 9.5), 2))

df_mobygames_required.info()

df_mobygames_required.rename(columns = {'Released': 'Released_year'}, inplace = True)

df_mobygames_required.info()

df_final = pd.concat([df_mobygames_required, df_google_games_required, df_video_games_required, df_video_games_required], axis = 0)

df_final.info()

df_final.drop(['Released_date'], axis = 1, inplace = True)

df_final.head()

genre_counts = df_final['Genre'].value_counts().reset_index()

def update_genres(genre):
    if ',' in genre:
        return genre.split(',')[0]
    elif '/' in genre:
        return genre.split('/')[0]
    elif '(rpg)' in genre:
        return 'role-playing'
    elif '1.9' in genre:
        return 'misc'
    else:
        return genre

df_final['Genre'] = df_final['Genre'].str.lower()
df_final['Genre'] = df_final['Genre'].apply(update_genres)
df_final['Genre'] = df_final['Genre'].str.replace(r'[^a-z-_]', '', regex = True)
df_final['Genre'] = df_final['Genre'].apply(update_genres)

df_final['Genre'] = df_final['Genre'].str.replace('role-playingrpg', 'role-playing')

genre_counts = df_final['Genre'].value_counts().reset_index()

genre_counts

df_final['Genre'] = df_final['Genre'].str.strip()
df_final['Genre'] = df_final['Genre'].str.replace('racingdriving', 'racing')
df_final['Genre'] = df_final['Genre'].str.replace('strategytactics', 'strategy')
df_final['Genre'] = df_final['Genre'].str.replace('specialedition', 'special_edition')

genre_counts = df_final['Genre'].value_counts().reset_index()
genre_counts

df_final.head()

df_final['Name'] = df_final['Name'].str.strip()

df_final.info()

df_final['Released_year'] = df_final['Released_year'].astype('int')

df_final['Rating'].value_counts()

def update_ratings(rating):
    if rating >= 10:
        return rating/20
    elif rating >= 5:
        return rating/2
    return rating

df_final['Rating'] = df_final['Rating'].apply(update_ratings)

df_final['Rating'].value_counts()

df_final.info()

df_final.head()

developers = df_appstore_games['Developer']

developers = list(developers.unique())

len(developers)

publisher = list(df_video_games['Publisher'].unique())
console = list(df_video_games['Platform'].unique())

audience_type = list(df_google_games['Content Rating'].unique())

audience_type.pop()

developers_list = []
publisher_list = []
audience_type_list = []
console_list = []

for _ in range(len(df_final)):
    developers_list.append(np.random.choice(developers))

for _ in range(len(df_final)):
    publisher_list.append(np.random.choice(publisher))

for _ in range(len(df_final)):
    audience_type_list.append(np.random.choice(audience_type))

for _ in range(len(df_final)):
    console_list.append(np.random.choice(console))

df_final['developers'] = pd.Series(developers_list)
df_final['console'] = pd.Series(console_list)
df_final['audience_type'] = pd.Series(audience_type_list)
df_final['publisher'] = pd.Series(publisher_list)

df_final.info()

df_final['tags'] = df_final['Genre'] + " " + df_final['developers'] + " " + df_final['console'] + " " + df_final['audience_type'] + " " + df_final['publisher']

df_final.head()

dataset = df_final[['Name', 'tags']]

dataset

"""

TFIDF takes too much time


from sklearn.feature_extraction.text import TfidfVectorizer
# apply stopwords and also give hard coded feature value - 8000
tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
vector = tfidf.fit_transform(dataset['tags']).toarray()
vector.shape"""

from gensim.models.fasttext import FastText as FT_gensim
import re
corpus = dataset['tags'].tolist()
sentences = [re.split(' ', str(sentence)) for sentence in corpus]
embedding_size = 30

FT_model = FT_gensim(vector_size=embedding_size, min_count=2, min_n=2, max_n=5, sg=1, negative=10,
                         sample=0.001, window=5, alpha=0.025, min_alpha=0.0001, epochs=50)

FT_model.build_vocab(sentences)

print('corpus_count: ', FT_model.corpus_count)
print('corpus_total_words: ', FT_model.corpus_total_words)

FT_model.train(sentences, epochs=FT_model.epochs, total_examples=FT_model.corpus_count, total_words=FT_model.corpus_total_words)

FT_vector = []

for item in corpus:
    FT_vector.append(FT_model.wv[str(item)])
FT_vector = np.asarray(FT_vector)


"""
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(FT_vector)

def recommend(game):
    index = dataset[dataset['Name'] == game].index[0]
    distances = sorted(list(enumerate(similarity[index])), reverse=True, key = lambda x:x[1])

    for i in distances[1:6]:
        print(dataset.iloc[i[0]].Name)
"""

from sklearn.cluster import KMeans
from scipy.spatial.distance import cdist

kmeanModel = KMeans(n_clusters=50, random_state=42).fit(FT_vector)
cluster_id = kmeanModel.predict(FT_vector)
dataset["cluster_id"] = cluster_id

def recommendation_system(game, dataset, FT_vector, FT_model):
  try:
    '''
    corpus = dataset['tags'].tolist()
    sentences = [re.split(' ', str(sentence)) for sentence in corpus]
    embedding_size = 30
    FT_model = FT_gensim(vector_size=embedding_size, min_count=2, min_n=2, max_n=5, sg=1, negative=10,
            sample=0.001, window=5, alpha=0.025, min_alpha=0.0001, epochs=50)
    FT_model.build_vocab(sentences)
    print('corpus_count: ', FT_model.corpus_count)
    print('corpus_total_words: ', FT_model.corpus_total_words)
    FT_model.train(sentences, epochs=FT_model.epochs, total_examples=FT_model.corpus_count, 
            total_words=FT_model.corpus_total_words)
    FT_vector = []
    for item in corpus:
        FT_vector.append(FT_model.wv[str(item)])
    FT_vector = np.asarray(FT_vector)
    '''
    top_k = 5
    title_row = dataset[dataset["Name"] == game].copy()
    #print(title_row)
    search_df = dataset[dataset["cluster_id"].isin(title_row["cluster_id"])].copy()
    #print(search_df)
    search_df = search_df.drop(search_df[search_df["Name"] == game].index)
    #print(search_df)

    search_df["Similarity"] = search_df.apply(lambda x: FT_model.wv.similarity(title_row["tags"], x["tags"]), axis=1)
    search_df["Similarity"] = search_df["Similarity"].apply(lambda x: np.mean(x))
    search_df.sort_values(by=["Similarity"], ascending=False, inplace=True)
    #print(search_df)
    return search_df[["Name"]].head(top_k)
  except Exception as e:
    print(e)

